

# **Desafio Pr√°tico - Ci√™ncia de Dados**

Este reposit√≥rio foi criado com o objetivo de apresentar o trabalho desenvolvido no estudo de caso para a treinar alguns conceitos da √°rea de **Ci√™ncia de Dados**.

## ***Introdu√ß√£o***

Este projeto tem como objetivo a cria√ß√£o de um modelo de classifica√ß√£o capaz de prever se um usu√°rio, baseado em suas intera√ß√µes em um site imobili√°rio, comprar√° ou n√£o uma casa. O modelo ser√° treinado utilizando um conjunto de dados que cont√©m informa√ß√µes demogr√°ficas e comportamentais dos usu√°rios, como idade, renda, tempo de navega√ß√£o no site, e intera√ß√£o com an√∫ncios.

O desafio √© usar essas vari√°veis para prever a decis√£o de compra, que √© representada pela vari√°vel alvo "Compra". Com isso, o projeto busca fornecer insights sobre o comportamento dos usu√°rios e como essas caracter√≠sticas influenciam a decis√£o de compra de um im√≥vel.

Ao longo deste reposit√≥rio, apresentamos um passo a passo detalhado do processo de constru√ß√£o do modelo, desde a an√°lise inicial dos dados at√© a avalia√ß√£o do desempenho do modelo final. O objetivo √© fornecer uma abordagem did√°tica para quem deseja aprender sobre t√©cnicas de aprendizado de m√°quina aplicadas a problemas reais de neg√≥cios.

## ***Descri√ß√£o do Projeto***

Este projeto √© um desafio pr√°tico desenvolvido como parte do processo seletivo para uma vaga de est√°gio em Ci√™ncia de Dados. O objetivo √© construir um modelo de classifica√ß√£o para prever se um usu√°rio de um site imobili√°rio comprar√° ou n√£o uma casa, com base em suas caracter√≠sticas demogr√°ficas e comportamentais.

Os dados foram divididos em dois conjuntos:

- **Conjunto de Treinamento**
  - 140 registros
  - Aproximadamente 70% do total
  - Este conjunto ser√° utilizado para treinar o modelo de aprendizado de m√°quina e realizar a valida√ß√£o inicial do desempenho.

- **Conjunto de Teste**
  - 60 registros
  - Aproximadamente 30% do total
  - Este conjunto ser√° utilizado para avaliar a efic√°cia do modelo treinado.

O **conjunto de treinamento** cont√©m dados sobre os usu√°rios e se eles compraram ou n√£o uma casa, informa√ß√µes que ser√£o usadas para treinar o modelo de classifica√ß√£o.

O **conjunto de teste** ser√° utilizado para testar o desempenho do modelo em dados n√£o vistos. Para esse conjunto, as respostas (compra ou n√£o compra) n√£o est√£o fornecidas, e o modelo ser√° respons√°vel por prever esses resultados.

Este projeto visa demonstrar as habilidades de an√°lise de dados, processamento de informa√ß√µes e constru√ß√£o de modelos preditivos, essenciais para o cargo de est√°gio em Ci√™ncia de Dados.

# **Etapas**

Muitos dos passos est√£o explicados diretamente no pr√≥prio Jupyter Notebook. Neste README, fornecerei apenas informa√ß√µes mais gerais sobre as etapas anteriores √† **interpreta√ß√£o dos resultados**, pois darei um foco maior a essa parte aqui.

Ambos os documentos se complementam, portanto, algumas informa√ß√µes presentes nesse README podem n√£o estar no Jupyter Notebook e vice-versa. Por isso, recomendo analisar cada etapa com base em ambos os textos para uma compreens√£o completa.



## ***0. Entendendo o Dataset***

Nesta primeira etapa, o objetivo √© importar as bibliotecas necess√°rias, carregar o dataset e realizar uma an√°lise preliminar para entender melhor os dados com os quais estamos lidando. Isso inclui visualizar as primeiras linhas, verificar os tipos de dados de cada coluna e entender a distribui√ß√£o dos dados. Tamb√©m foi realizado uma an√°lise para identificar valores at√≠picos e valores ausentes.

Dentre as principais atividades realizadas, temos:

- **Importa√ß√£o de Bibliotecas**: Foi usado bibliotecas como Pandas para manipula√ß√£o dos dados, Matplotlib e Seaborn para visualiza√ß√µes, e Scikit-learn para modelagem.
- **Carregamento e Visualiza√ß√£o Inicial**: Foi carregado o dataset e visualizamos as primeiras linhas e tipos de dados de cada coluna.
- An√°lise Descritiva: Tamb√©m foi verificado estat√≠sticas b√°sicas das vari√°veis num√©ricas e a distribui√ß√£o da vari√°vel alvo ("Compra").
- Identifica√ß√£o de Problemas: E por fim, foi investigado a presen√ßa de valores ausentes e poss√≠veis outliers, como valores negativos no "Tempo no Site (min)".

Essa etapa ajudou a entender melhor os dados e a preparar o terreno para uma an√°lise explorat√≥ria mais acertiva.

## ***1. An√°lise Explorat√≥ria de Dados (AED)***

A An√°lise Explorat√≥ria de Dados tem como objetivo obter uma compreens√£o mais profunda dos dados, identificar problemas potenciais e gerar hip√≥teses sobre o comportamento das vari√°veis.

Dentre as principais atividades realizadas, temos:
- **An√°lise das Rela√ß√µes com a Coluna Alvo**: Foram gerados gr√°ficos para analisar a distribui√ß√£o de cada vari√°vel e como ela se relaciona com a vari√°vel alvo Compra.
- **Matriz de Correla√ß√£o**: A correla√ß√£o entre as vari√°veis num√©ricas foi analisada para verificar rela√ß√µes significativas entre elas.
- **Outros Gr√°ficos**: Al√©m disso, gr√°ficos como o scatterplot foram gerados para visualizar melhor as rela√ß√µes entre as vari√°veis.

Al√©m disso, para uma an√°lise mais detalhada e visual, foi utilizada a biblioteca [**ydata-profiling**](https://github.com/ydataai/ydata-profiling). Essa ferramenta automatiza a an√°lise explorat√≥ria, gerando relat√≥rios completos que oferecem insights valiosos sobre o dataset, como distribui√ß√£o das vari√°veis, correla√ß√µes e poss√≠veis problemas. 

## ***2. Pr√©-Processamento***

Ap√≥s a an√°lise explorat√≥ria, a etapa de pr√©-processamento √© fundamental para garantir a qualidade dos dados antes de aplicar modelos de aprendizado de m√°quina. Durante este processo, abordamos tr√™s pontos principais.

### **2.1 Tratamento de valores nulos**

O tratamento de valores nulos √© uma etapa crucial no pr√©-processamento de dados, pois valores ausentes podem impactar diretamente a performance e a precis√£o dos modelos de aprendizado de m√°quina.

Podem gerar problemas como:
- **Perda de Informa√ß√£o**
  - Uma vez que se os valores ausentes forem ignorados, o modelo pode ser treinado com dados incompletos, o que pode levar a resultados imprecisos ou enviesados.
- **Erro de Execu√ß√£o de Algoritmos**
  - Pois, muitos algoritmos de aprendizado de m√°quina n√£o conseguem lidar com valores nulos e podem gerar erros durante o treinamento ou a previs√£o.
- **Impacto nas M√©tricas**
  - Em modelos de regress√£o ou classifica√ß√£o, a presen√ßa de valores nulos pode afetar a an√°lise de erros, tornando as m√©tricas de avalia√ß√£o

Abaixo esta um gr√°fico mostrando alguns dos valores nulos achados no dataset analisado.

![valores_nulos](https://github.com/user-attachments/assets/d051b18c-0802-44d0-b9bc-974663fdd501)

Existem algumas abordagens para lidar com valores nulos.
- **Removendo os Dados Nulos**
  
 O objetivo aqui √© excluir os registros que cont√™m valores nulos.

Essa abordagem √© adequada quando apenas alguns registros est√£o incompletos. No entanto, pode prejudicar a qualidade do modelo, pois, ao remover um registro, tamb√©m perdemos informa√ß√µes valiosas de outras colunas associadas a ele.

- **Imputa√ß√£o de Valores (M√©dia/Mediana/Moda)**

O objetivo √© preencher os registros com valores nulos com alguns valores estimados com base nos dados dispon√≠veis.

Para **vari√°veis num√©ricas**, √© comum substituir os valores nulos pela m√©dia ou pela mediana, dependendo da distribui√ß√£o dos dados.

A **substitui√ß√£o pela m√©dia** √© uma boa op√ß√£o quando os dados seguem uma distribui√ß√£o normal ou sim√©trica e quando n√£o h√° outliers que possam distorcer seu valor, pois a presen√ßa desses extremos pode comprometer a qualidade dos modelos de machine learning.

A **substitui√ß√£o pela mediana**, por outro lado, √© prefer√≠vel quando os dados possuem uma distribui√ß√£o assim√©trica ou desconhecida. Isso ocorre porque a m√©diana √© mais robusta a outliers, impedindo que valores extremos distor√ßam o conjunto de dados, j√° que ela representa o valor central da amostra.

Para **vari√°veis categ√≥ricas**, √© comum substituir os valores nulos pela moda, ou seja, pelo valor mais frequente na vari√°vel. Essa √© uma abordagem r√°pida e eficiente na maioria dos casos.

- **Imputa√ß√£o com Algoritmos de Machine Learning**

Essa √© uma abordagem mais robusta, na qual algoritmos de machine learning s√£o utilizados para prever os valores ausentes com base em outras caracter√≠sticas do conjunto de dados. Para isso, existem t√©cnicas como KNN ou a Regress√£o	Log√≠stica.

Na **imputa√ß√£o por KNN**, os valores ausentes s√£o preenchidos com base nos valores dos vizinhos mais pr√≥ximos, levando em considera√ß√£o as caracter√≠sticas semelhantes entre as amostras.

J√° na **imputa√ß√£o por Regress√£o Log√≠stica**, utiliza-se um modelo de regress√£o log√≠stica para prever os valores ausentes com base nas outras vari√°veis do conjunto de dados.

Essas t√©cnicas podem ser utilizadas quando a quantidade de dados ausentes √© significativamente grande e a imputa√ß√£o simples n√£o √© suficiente para preservar a qualidade do modelo.


### **2.2 Tratamento das Vari√°veis Categ√≥ricas**

A convers√£o de vari√°veis categ√≥ricas em formatos num√©ricos √© uma outra etapa essencial no pr√©-processamento de dados, especialmente quando se trabalha com modelos de aprendizado de m√°quina.

Isso ocorre porque a maioria dos algoritmos de aprendizado de m√°quina exige entradas num√©ricas para realizar c√°lculos e determinar padr√µes. Como por exemplo, c√°lculos de dist√¢ncia, correla√ß√µes entre outras m√©tricas.

Portanto, o objetivo principal desse tratamento √© aprimorar a efici√™ncia dos modelos que ser√£o desenvolvidos.

Devido √† baixa complexidade do dataset e ao fato de estarmos lidando com vari√°veis categ√≥ricas que podem assumir apenas valores bin√°rios, optei por realizar a **codifica√ß√£o direta** dessas vari√°veis. Essa escolha se mostrou eficiente, pois, como as categorias envolvem apenas dois valores poss√≠veis (como, "sim" ou "n√£o", "0" ou "1"), a convers√£o para formato num√©rico pode ser feita diretamente, sem a necessidade de recorrer a t√©cnicas mais complexas, como one-hot encoding.

**One-hot encoding** √© uma t√©cnica amplamente utilizada no tratamento de vari√°veis categ√≥ricas, especialmente quando um atributo pode assumir mais de dois valores poss√≠veis. Essa abordagem consiste em criar uma nova coluna para cada categoria, onde um valor bin√°rio (0 ou 1) indica a presen√ßa ou aus√™ncia de cada categoria para uma observa√ß√£o espec√≠fica.

Seu uso √© fundamental nesses casos, pois evita que os modelos interpretem erroneamente a exist√™ncia de uma ordem ou rela√ß√£o hier√°rquica entre os valores transformados, o que poderia distorcer os resultados.

### **2.3 Tratamento de Valores Inconsistentes**

Essa etapa, √© fundamental no pr√©-processamento de dados, pois, assim como nos casos anteriores, valores err√¥neos ou que n√£o fazem sentido podem comprometer a qualidade e a confiabilidade do modelo de aprendizado de m√°quina.

Entre os tipos mais comuns de inconsist√™ncias est√£o os valores negativos em vari√°veis onde esses valores n√£o deveriam existir, como em idade, pre√ßo, quantidade de produtos vendidos, entre outros.

Normalmente, valores negativos nessas vari√°veis indicam erros de coleta, falhas de entrada ou dados corrompidos, e sua presen√ßa pode gerar resultados distorcidos durante o treinamento do modelo. Portanto, √© crucial identificar e corrigir esses valores antes de alimentar o modelo.

Como abordagens para lidar com esses casos, podemos **substituir os valores inconsistentes** por valores v√°lidos, como a m√©dia ou a mediana. Outra alternativa √© optar pela **remo√ß√£o dos registros** que cont√™m esses valores inconsistentes. Uma abordagem adicional, embora menos utilizada devido √† complexidade em determinadas situa√ß√µes, √© **consultar o provedor dos dados** para verificar se a inconsist√™ncia √©, de fato, um erro ou n√£o.

No caso desse projeto, foi observado a presen√ßa de valores negativos na coluna ***"Tempo no Site (min)"***, o que claramente n√£o faz sentido, j√° que o tempo de navega√ß√£o em um site n√£o pode ser negativo.

A abordagem adotada foi substituir os valores negativos por valores nulos (NaN) e, em seguida, realizar a substitui√ß√£o desses valores nulos pela **mediana**. A escolha da mediana foi feita com base no que foi comentado anteriormente, j√° que ela √© mais robusta a valores extremos e outliers, garantindo uma imputa√ß√£o mais confi√°vel e representativa do tempo que um usu√°rio fica no site, sem ser influenciada por poss√≠veis distor√ß√µes nos dados. 

Essa estrat√©gia assegura que os dados sejam consistentes e apropriados para a modelagem, melhorando a qualidade do modelo de aprendizado de m√°quina.

Por exemplo, imagine que a coluna "Tempo no Site (min)" contenha um valor muito alto, como 1000 minutos, o que poderia ser um outlier.
- Nesse caso, a **m√©dia** seria influenciada por esse valor extremo, tornando-a maior em rela√ß√£o aos demais valores da coluna.
- J√° a **mediana**, por outro lado, continuaria refletindo de maneira mais fiel o comportamento central dos dados, pois n√£o √© impactada pelos eventuais outliers.


## ***3. Constru√ß√£o do Modelo de Machine Learning***

Nesta etapa, o foco √© construir e treinar o modelo de machine learning para resolver o problema proposto. Ap√≥s o tratamento dos dados, incluindo a remo√ß√£o e substitui√ß√£o de valores nulos, al√©m da transforma√ß√£o das vari√°veis categ√≥ricas, o pr√≥ximo passo √© selecionar o modelo adequado para obter o melhor desempenho.

Para a constru√ß√£o do modelo de machine learning, adotei uma abordagem comparativa, utilizando diferentes algoritmos de classifica√ß√£o para avaliar qual oferece o melhor desempenho para o problema em quest√£o.

Para isso, foram utilizados quatro modelos para a classifica√ß√£o: 
- **Regress√£o Log√≠stica**
- **√Årvore de Decis√£o**
- **Random Forest**  
- **Rede Neural**

A escolha da rede neural foi feita para analisar os resultados utilizando um modelo de maior complexidade em compara√ß√£o com os demais, a fim de verificar se h√° diferen√ßas significativas nos resultados obtidos.

Dividi essa etapa em duas abordagens. Primeiro, realizaremos a previs√£o sem o uso do m√©todo de valida√ß√£o cruzada. Em seguida, aplicaremos o m√©todo de valida√ß√£o cruzada e compararemos os resultados obtidos em ambos os casos.

### **3.1 Previs√£o sem Valida√ß√£o Cruzada**
Nesta etapa, foram realizados os seguintes passos para gerar os modelos:

- **Separa√ß√£o das vari√°veis independentes e da vari√°vel alvo**: Organizando os dados para identificar as vari√°veis explicativas e a vari√°vel a ser prevista.
- **Divis√£o dos dados em treino e teste**: Os dados foram divididos em 70% para treinamento e 30% para teste. Embora n√£o exista uma divis√£o fixa, essa √© a propor√ß√£o mais comum utilizada.
- **Treinamento dos quatro modelos selecionados**: Os modelos foram treinados com base no conjunto de dados de treinamento.
- **Avalia√ß√£o da performance dos modelos**: A performance dos modelos foi avaliada utilizando o conjunto de teste, a fim de verificar como eles se comportam com dados novos
- **Exibi√ß√£o dos relat√≥rios de classifica√ß√£o**: Foram gerados relat√≥rios contendo as m√©tricas de avalia√ß√£o, como precis√£o, recall, F1-score e acur√°cia, para uma an√°lise detalhada do desempenho de cada modelo.

Ap√≥s a conclus√£o desses passos, foi gerado um gr√°fico exibindo os resultados de acur√°cia obtidos pelos modelos, como pode ser observado a seguir.

![resultados_sem_cv](https://github.com/user-attachments/assets/6273ae19-445d-492f-8efe-3eb789bda7d9)


Podemos ver que o modelo que apresentou o ***melhor desempenho*** foi a **√Årvore de Decis√£o**, que obteve a maior acur√°cia entre todos os modelos testados. Isso sugere que a simplicidade e a capacidade de interpreta√ß√£o dessa t√©cnica foram vantajosas para este conjunto de dados, permitindo que ela capturasse de forma eficaz as rela√ß√µes entre as vari√°veis.

Os modelos que apresentaram os ***piores desempenhos*** foram o **Random Forest** e a **Rede Neural (MLP)**. Ambos ficaram atr√°s da √Årvore de Decis√£o em termos de acur√°cia. Isso pode indicar que, neste caso espec√≠fico, esses modelos mais complexos n√£o se ajustaram t√£o bem aos dados ou que a configura√ß√£o dos par√¢metros pode n√£o ter sido a mais adequada, o que comprometeu sua capacidade de generaliza√ß√£o para o conjunto de teste.

### **3.2 Previs√£o com Valida√ß√£o Cruzada**

A valida√ß√£o cruzada √© uma t√©cnica utilizada em aprendizado de m√°quina para avaliar a performance de um modelo de forma mais robusta. Ela tem como objetivo reduzir a varia√ß√£o nos resultados e garantir que o modelo n√£o esteja superajustado aos dados de treinamento.

O termo **underfitting**, √© usado quando um modelo √© muito simples para capturar os padr√µes e rela√ß√µes presentes nos dados. Isso acontece geralmente quando o modelo n√£o possui complexidade suficiente para aprender as caracter√≠sticas subjacentes dos dados, o que leva a um desempenho fraco tanto no conjunto de treinamento quanto no conjunto de teste.

J√° o termo **overfitting**, √© usado quando o modelo "aprende demais" os detalhes dados de treinamento, capturando at√© padr√µes irrelevantes ou espec√≠ficos demais para esse conjunto de dados. Essa caracter√≠sticas, que a princ√≠pio parece ser positiva, faz com que o modelo tenha um desempenho muito bom no conjunto de treinamento, mas se saia mal no conjunto de teste, isso √©, o modelo se adapta excessivamente aos dados de treinamento, tornando-se muito espec√≠fico e, portanto, menos eficaz quando exposto a dados desconhecidos.

Logo, a valida√ß√£o cruzada √© uma das t√©cnicas usadas pare resolver esse problema.

#### **3.2.1 Funcionamento da Valida√ß√£o Cruzada**

Na valida√ß√£o cruzada, o conjunto de dados √© dividido em m√∫ltiplos subconjuntos, os chamados ***folds***.

O conjunto de dados √© dividido em **k folds** de tamanho aproximadamente igual, para cada uma das k itera√ß√µes, o modelo √© treinado em **k-1 folds** e testado no fold restante. Isso √©, ele √© treinado k vezes, utilizando um fold diferente como conjunto de teste a cada vez

O desempenho do modelo √© avaliado em cada itera√ß√£o, e ao final, as m√©tricas de desempenho s√£o **m√©dia das avalia√ß√µes** de todas as itera√ß√µes.

Essa abordagem √© extremamente interessante, pois nos permite ter um maior controle sobre eventuais distor√ß√µes que poderiam ocorrer devido a uma √∫nica divis√£o de dados entre treino e teste. Ao realizar a valida√ß√£o cruzada, temos v√°rias divis√µes dos dados, o que reduz significativamente o risco de uma divis√£o espec√≠fica, que poderia beneficiar ou prejudicar o modelo, tornando-o enviesado.

Com mais separa√ß√µes dos dados, garantimos que o modelo seja avaliado em diferentes contextos e condi√ß√µes, o que ajuda a obter uma medida mais confi√°vel e generaliz√°vel de seu desempenho. Isso torna a avalia√ß√£o do modelo mais robusta, pois evitamos que o desempenho do modelo seja afetado por uma divis√£o particular que poderia n√£o ser representativa do comportamento real dos dados.

Esse tipo de valida√ß√£o cruzada tem o nome de ***k-fold cross-validation***.

#### **3.2.2 Etapas**

As etapas seguem basicamente a mesma estrutura da etapa anterior, com algumas mudan√ßas pontuais. Entretanto, etapas como a separa√ß√£o das vari√°veis e a divis√£o entre treino e teste n√£o s√£o realizadas de maneira expl√≠cita, como na etapa anterior. 

Isso ocorre porque podemos reutilizar a separa√ß√£o das vari√°veis, e, ao tratar-se de valida√ß√£o cruzada, a pr√≥pria fun√ß√£o ***cross_val_score()*** ser√° respons√°vel por dividir os dados em treino e teste automaticamente, al√©m de calcular e retornar a acur√°cia m√©dia durante o processo de valida√ß√£o cruzada.

Outra informa√ß√£o que √© gerada devido a valida√ß√£o cruzada √© o **Desvio Padr√£o.**
- Ele fornece uma medida de varia√ß√£o ou dispers√£o nos resultados das diferentes itera√ß√µes de treinamento e teste, isso √©, indica o quanto os desempenhos do modelo variam entre os diferentes subconjuntos de dados usados no processo de valida√ß√£o cruzada.

Ap√≥s a conclus√£o desses passos, foi gerado um gr√°fico exibindo os resultados de acur√°cia obtidos pelos modelos, como pode ser observado a seguir.

![resultado_com_cv](https://github.com/user-attachments/assets/6e7ae7f3-37ec-402d-854b-eca90046c75b)

Podemos obervar que o modelo que apresentou o **melhor desempenho** nesse novo contexto foi a **Rede Neural (MLP)**, obtendo a maior acur√°cia entre os demais. 

J√° o modelo que apresentou o **pior desempenho** foi a **√Årvore de Decis√£o**, obtendo a pior acur√°cia.

### **3.3 Compara√ß√£o**

Uma vez realizada ambas abordagens, vamos analisar um pouco as diferen√ßas obtidas.

![comparacao](https://github.com/user-attachments/assets/3f15f254-2439-4cc1-beb5-82114a468592)

Uma observa√ß√£o interessante √© que os pap√©is dos modelos se inverteram ao utilizarmos a valida√ß√£o cruzada na constru√ß√£o dos modelos. 

Enquanto, ***sem a valida√ß√£o cruzada***, o melhor modelo era a **√Årvore de Decis√£o** e o pior modelo era a **Rede Neural**, com a introdu√ß√£o da ***valida√ß√£o cruzada***, a **√Årvore de Decis√£o** passou a ter o pior desempenho, enquanto a **Rede Neural** se destacou como o melhor modelo.

Esse fen√¥meno pode ser explicado pelo fato de que a valida√ß√£o cruzada oferece uma avalia√ß√£o mais robusta e generalizada do desempenho dos modelos. Ela permite que o modelo seja testado em diferentes divis√µes dos dados, reduzindo o risco de sobreajuste (overfitting) e proporcionando uma avalia√ß√£o mais fiel √† sua capacidade de generaliza√ß√£o

Assim, enquanto a **√Årvore de Decis√£o** pode ter se beneficiado de uma divis√£o espec√≠fica dos dados, a **Rede Neural**, com sua capacidade de capturar padr√µes mais complexos, teve seu potencial melhor aproveitado e mostrou-se mais eficaz com a valida√ß√£o cruzada.

Logo, podemos dizer que no caso dos modelos sem valida√ß√£o
cruzada a **√Årvore de Decis√£o** pode ter se sa√≠do melhor porque se ajustou bem aos dados de treino espec√≠ficos, sem a preocupa√ß√£o de generalizar em diferentes conjuntos de dados. Isso pode ter dado uma falsa sensa√ß√£o de bom desempenho.

J√° com a valida√ß√£o cruzada, a **Rede Neural** mostrou sua capacidade de generaliza√ß√£o, uma vez que foi exigida uma avalia√ß√£o mais rigorosa e robusta do desempenho do modelo.

## ***4. Ajustando Hiperpar√¢metros***

Para aprimorar ainda mais os resultados obtidos, podemos realizar **ajustes nos hiperpar√¢metros** de cada modelo. Essas modifica√ß√µes visam otimizar o desempenho de cada algoritmo, buscando alcan√ßar resultados mais satisfat√≥rios e adaptados √†s caracter√≠sticas espec√≠ficas dos dados.

Hiperpar√¢metros s√£o par√¢metros que controlam o comportamento de um modelo de Machine Learning, mas que n√£o s√£o aprendidos diretamente a partir dos dados durante o processo de treinamento.

Ao contr√°rio dos par√¢metros do modelo (como os coeficientes em uma regress√£o linear ou os pesos em uma rede neural), os hiperpar√¢metros s√£o definidos antes do treinamento e t√™m um impacto direto na capacidade do modelo de aprender e generalizar.

Cada modelo possui um conjunto exclusivo de hiperpar√¢metros, que varia de acordo com o tipo de algoritmo utilizado. Abaixo, est√£o listados os hiperpar√¢metros empregados neste projeto.

- [**Regress√£o Log√≠stica**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)
  - **Regulariza√ß√£o (C)**: controla a quantidade de penaliza√ß√£o aplicada para evitar overfitting. Valores menores de C aplicam maior penaliza√ß√£o, e valores maiores permitem que o modelo se ajuste mais aos dados. 
  - **Solver**: Algoritmo utilizado para otimizar a fun√ß√£o de custo
- [**√Årvore de Decis√£o**](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)
  - **Profundidade m√°xima (max_depth)**: Limita a profundidade da √°rvore, controlando a complexidade do modelo. Um valor muito alto pode causar overfitting, enquanto um valor muito baixo pode causar underfitting.
  - **N√∫mero m√≠nimo de amostras para dividir um n√≥ (min_samples_split)**: Define o n√∫mero m√≠nimo de amostras necess√°rias para realizar uma divis√£o, ajudando a controlar a complexidade do modelo.

- [**Random Forest**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)
  - **N√∫mero de √°rvores (n_estimators)**: N√∫mero de √°rvores que comp√µem a floresta, mais √°rvores podem aumentar a precis√£o, mas tamb√©m podem aumentar o tempo de treinamento. 
  - **Profundidade m√°xima (max_depth)**: Limita a profundidade m√°xima das √°rvores individuais na floresta.
  - **N√∫mero m√≠nimo de amostras para dividir um n√≥ (min_samples_split)**: Define o n√∫mero m√≠nimo de amostras necess√°rias para realizar uma divis√£o. 
- [**Rede Neural**](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)
  - **Tamanho da camada oculta (hidden_layer_sizes)**: Define o n√∫mero de neur√¥nios e camadas ocultas.
  - **Fun√ß√£o de Ativa√ß√£o (activation)**: Determina quais fun√ß√µes de ativa√ß√£o ser√£o usadas, nese caso foi usado a "relu" e a "tanh".
  - **Alpha**: Controla a regulariza√ß√£o L2.

A escolha desses par√¢metros foi baseada na documenta√ß√£o fornecida pelo Scikit-learn, cujos detalhes est√£o anexados nos nomes dos respectivos modelos.

Uma vez definidos alguns poss√≠veis valores para esses par√¢metros, podemos utilizar uma t√©cnica chamada ***GridSearchCV***, que tem como objetivo otimizar os hiperpar√¢metros de um modelo de machine learning. Essa t√©cnica permite encontrar a melhor combina√ß√£o de par√¢metros, resultando no melhor desempenho do modelo. Ela funciona realizando uma busca exaustiva em um espa√ßo pr√©-definido de valores para os hiperpar√¢metros especificados.

Seu funcionamento √© teoricamente simples, ele avalia todas as combina√ß√µes poss√≠veis dos par√¢metros fornecidos, treinando e avaliando o modelo para cada conjunto de hiperpar√¢metros.

### **4.1 Etapas**

- **Defini√ß√£o de um conjunto de par√¢metros**: Para cada modelo, voc√™ define um conjunto de hiperpar√¢metros a serem ajustados.
- **Treinamento e avalia√ß√£o**: O algoritmo treina e avalia o modelo para cada combina√ß√£o poss√≠vel desses par√¢metros, utilizando valida√ß√£o cruzada.
- **Sele√ß√£o do melhor modelo**: Ap√≥s a execu√ß√£o do grid search, o modelo com a melhor combina√ß√£o de hiperpar√¢metros √© selecionado.

Essa abordagem √© extremamente vantajosa, pois garante a identifica√ß√£o da melhor configura√ß√£o para os modelos dentro dos par√¢metros especificados. 

Seu √∫nico por√©m √© o alto custo computacional, j√° que, por se tratar de uma busca exaustiva, pode ser bastante cara, especialmente se o espa√ßo de busca for grande, ou seja, se houver muitos par√¢metros a serem ajustados.

Abaixo podemos verificar os resultados obtidos ap√≥s a aplica√ß√£o dessa ferramenta.

![otimizados](https://github.com/user-attachments/assets/00b43a89-0c34-436c-bb4d-b72fe1087fa1)

Dessa forma, proporciona um ***ajuste fino dos hiperpar√¢metros***, o ***evitamento de underfitting e overfitting*** e uma ***escolha mais assertiva dos par√¢metros***.

Por fim, temos a compara√ß√£o dos experimentos realizados.

### **Interpreta√ß√£o por Modelo**

![comparacao_experimetos](https://github.com/user-attachments/assets/69a76b02-99e9-4d3d-856d-130ccc9e520f)

***Regress√£o Log√≠stica***
- Os resultados mostram uma clara melhoria ao usar GridSearchCV, pois a busca por par√¢metros mais adequados melhorou a performance consistentemente

***√Årvore de Decis√£o***
-  A queda inicial com CV (de 65,33% para 54,50%) sugere que o modelo sofreu overfitting na divis√£o inicial. 
- O GridSearchCV recuperou parte da performance, mas o ajuste de par√¢metros n√£o foi suficiente para superar a divis√£o simples.

***Random Forest***
 - Houve uma melhoria consistente, indicando que o ajuste de hiperpar√¢metros ajudou a aumentar a generaliza√ß√£o do modelo

***MLP***
  -  O GridSearchCV n√£o melhorou em rela√ß√£o √† CV porque o modelo j√° estava bem ajustado antes.
  - Isso pode ocorrer se os valores padr√£o dos hiperpar√¢metros j√° forem pr√≥ximos do ideal. 
  - Talvez outras configura√ß√µes na rede poderiam melhorar ainda mais o resultado obtido.

√â poss√≠vel que tenha ocorrido um **overfitting** na divis√£o simples da √°rvore de decis√£o, o que explicaria o desempenho aparentemente melhor nesse cen√°rio em rela√ß√£o √† valida√ß√£o cruzada e ao GridSearchCV.

Podemos concluir que ***GridSearchCV*** √© uma ferramenta poderosa, mas n√£o garante sempre o melhor resultado no conjunto de teste, por mais que garanta a melhor configura√ß√£o de hiperpar√¢metros. 

## ***5. Interpreta√ß√£o de Algumas M√©tricas***

Nesta etapa, o foco √© analisar como as caracter√≠sticas do conjunto de dados influenciam as previs√µes dos modelos.

### **5.1 An√°lise das Features Mais Influentes**

Uma parte fundamental da interpreta√ß√£o dos resultados √© a identifica√ß√£o das features mais influentes nas previs√µes de cada modelo. Ao analisar a import√¢ncia das vari√°veis, podemos entender quais atributos t√™m o maior impacto no processo de tomada de decis√£o dos modelos de machine learning. Os modelos possuem algumas formas distintas de realizar essa an√°lise.

Modelos baseados em √°rvoes, como **√Årvore de Decis√£o** e **Random Forest** possuem m√©todos internos que avaliam a import√¢ncia relativa das features. 
- Nele, features com maior pontua√ß√£o s√£o mais influentes para a previs√£o.
- Esse m√©todo retorna um vetor com a import√¢ncia relativa de cada vari√°vel.
  - O valor de cada elemento do vetor est√° entre 0 e 1, e a soma das import√¢ncias de todas as vari√°veis ser√° igual a 1.
  - Para utiliz√°-lo bastar o seguinte comando: ***modelo_arvore.feature_importances_***.

Modelos lineares, como a **Regress√£o Log√≠stica**, produzem coeficientes que representam a for√ßa e a dire√ß√£o do impacto de cada feature na previs√£o. 
- Um coeficiente positivo indica que o aumento do valor da vari√°vel est√° associado a um aumento na probabilidade do evento ocorrer.
- Um coeficiente negativo sugere o contr√°rio.
- Valores maiores indicam um maior impacto da feature na previs√£o.

Em **redes neurais**, especialmente em arquiteturas como o MLP (Perceptron Multicamadas), n√£o h√° uma medida expl√≠cita de "import√¢ncia das vari√°veis" como em modelos tradicionais, como √Årvores de Decis√£o ou Random Forest. 

Uma maneira de interpretar a import√¢ncia das vari√°veis em uma **Rede Neural (MLP)** √© analisar os pesos das camadas. Esses pesos representam a for√ßa das conex√µes entre os neur√¥nios em diferentes camadas e determinam como cada vari√°vel de entrada afeta a previs√£o final.

Para um modelo MLP, as vari√°veis de entrada est√£o conectadas √† camada inicial da rede, e seus pesos s√£o ajustados durante o treinamento. A an√°lise dos pesos das camadas pode fornecer insights sobre a import√¢ncia de cada vari√°vel no modelo. 

Com base nessa contextualiza√ß√£o, vamos aprofundar a an√°lise dos resultados.

- **Regress√£o Log√≠stica**
  
![features_regressao](https://github.com/user-attachments/assets/f7ace5b7-3b5c-46e5-9645-0b1615f82eb4)

Com base no gr√°fico, conseguimos concluir que as features com maior impacto para esse modelo foram, ***"An√∫ncio Clicado"*** e ***"G√™nero"***.

- **√Årvore de Decis√£o**
  
![features_arvore](https://github.com/user-attachments/assets/fcfcea44-2a15-4fc5-840d-6978e4beb77f)

Para a √°rvore, as features que melhor se sobressairam foi ***"Tempo no Site (min)"*** e ***"G√™nero"***.

- **Random Forest**

![features_forest](https://github.com/user-attachments/assets/6185284f-268b-4cfb-b4cd-cb1147397b90)

Para a random forest, as features ***"Tempo no Site (min)"*** e ***"Idade"*** foram as que mais tiveram impacto.

- **Rede Neural (MLP)**

![features_mlp](https://github.com/user-attachments/assets/6a820743-0bb6-4e20-9f8a-51cd7560d908)

E para o MLP ***"An√∫ncio Clicado"*** e ***"Idade"*** tiveram maior peso no resultado final.

#### **5.1.1 Conclus√µes**

A partir desses gr√°ficos podemos tentar inferir algumas informa√ß√µes.

Para ambos os modelos que apresentaram os melhores resultados **(Regress√£o Log√≠stica: 67,5% e MLP: 67%)**, a vari√°vel com maior impacto na previs√£o assertiva foi o ***"An√∫ncio Clicado"***. 

Isso destaca que indiv√≠duos que clicaram no an√∫ncio demonstram uma maior propens√£o a realizar a compra do im√≥vel. Essa descoberta sugere que o clique no an√∫ncio √© um forte indicador de interesse genu√≠no, o que pode ser utilizado como um fator chave para prever a convers√£o em vendas.

Em contrapartida, para os modelos com desempenho inferior, como **√Årvore de Decis√£o (61%)** e **Random Forest (62,5%)**, observamos que a vari√°vel com maior impacto foi ***"Tempo no Site (min)"***. No entanto, isso sugere que, embora o tempo passado no site seja relevante para esses modelos, ele n√£o parece ser um bom indicativo da probabilidade de convers√£o em vendas.

Essa an√°lise fica mais clara quando comparamos com os modelos de melhor desempenho, **Regress√£o Log√≠stica (67,5%)** e **MLP (67%)**, onde o ***"Tempo no Site (min)"*** teve um peso significativamente menor entre as vari√°veis. Isso refor√ßa a ideia de que, ao contr√°rio do que sugerem os modelos menos eficazes, essa feature n√£o possui um forte poder preditivo para determinar se uma compra ser√° realizada ou n√£o.

Outra observa√ß√£o importante √© que, por mais intuitivo e tentador que seja imaginar que a vari√°vel **Renda Anual** teria uma grande influ√™ncia nos modelos, isso n√£o se concretizou. Em todos os modelos testados, a ***"Renda Anual (em $)"*** n√£o foi nem mesmo a segunda vari√°vel mais importante, o que nos mostra que, muitas vezes, nossa intui√ß√£o sobre quais fatores s√£o mais relevantes pode n√£o refletir a realidade dos dados. Essa an√°lise refor√ßa a import√¢ncia de basear as decis√µes em evid√™ncias e resultados quantitativos, em vez de apenas suposi√ß√µes.


### **5.2 An√°lise das M√©tricas de Desempenho**

Essa an√°lise ser√° feita sobre os modelos gerados a partir do cross-validation.

Vamos agora analisar um aspecto que frequentemente √© negligenciado, mas que pode fornecer informa√ß√µes valiosas, o ***Desvio Padr√£o***. 

Abaixo, apresentamos uma imagem com os valores de desvio padr√£o obtidos para os modelos previamente discutidos.

![DesvioPadraoVC](https://github.com/user-attachments/assets/ee1f1a5d-8613-4e0c-a1f0-5341a7119da4)

Conceitualmente, o ***Desvio Padr√£o*** fornece informa√ß√µes importantes sobre a consist√™ncia do desempenho de um modelo:

- Se o **desvio padr√£o for baixo**, isso indica que o modelo apresenta um desempenho consistente em diferentes subconjuntos de dados. Isso sugere que o modelo √© est√°vel e n√£o est√° excessivamente ajustado a um subconjunto espec√≠fico dos dados, o que √© um bom sinal de que ele tem boa capacidade de generaliza√ß√£o.

- Se o **desvio padr√£o for alto**, isso indica que o desempenho do modelo varia consideravelmente entre as diferentes itera√ß√µes. Isso pode ser um indicativo de que o modelo est√° muito sens√≠vel √† divis√£o dos dados, n√£o est√° generalizando bem ou at√© pode estar sofrendo de overfitting. Em outras palavras, o modelo pode estar capturando padr√µes espec√≠ficos do conjunto de treino que n√£o se aplicam ao conjunto de teste.

A **Regress√£o Log√≠stica** apresentou um desvio padr√£o baixo, isso sugere que a acur√°cia do modelo n√£o sofre grandes flutua√ß√µes entre as diferentes itera√ß√µes da valida√ß√£o cruzada.

A **√Årvore de Decis√£o** tamb√©m apresenta um desvio padr√£o relativamente baixo, mostrando baixas altera√ß√µes durante as itera√ß√µes.

A **Random Forest** √© a que apresentou o maior desvio padr√£o, indicando que o desenpenho do modelo teve uma maior varia√ß√£o entre as itera√ß√µes, sendo assim mais sens√≠vel a diferentes subconjuntos dos dados.

E por fim , a **Rede Neural (MLP)** apresenta ser um dos mais robustos, j√° que acur√°cia n√£o varia de significativamente entre as intera√ß√µes da valida√ß√£o cruzada. 

## ***6. Conclus√£o***

Este projeto teve como objetivo desenvolver e avaliar diferentes modelos de machine learning para prever a probabilidade de um cliente realizar a compra de um im√≥vel com base em um conjunto de caracter√≠sticas. Atrav√©s do uso de t√©cnicas como valida√ß√£o cruzada e ajuste de hiperpar√¢metros, conseguimos otimizar e comparar a performance de diversos algoritmos, incluindo **Regress√£o Log√≠stica**, **√Årvore de Decis√£o**, **Random Forest** e **Rede Neural (MLP)**.

A partir dos resultados obtidos, foi poss√≠vel observar que o uso da ***valida√ß√£o cruzada*** teve um impacto significativo no desempenho dos modelos, proporcionando uma maior generaliza√ß√£o e redu√ß√£o do risco de **overfitting**. Modelos como a **Rede Neural (MLP)**, que inicialmente apresentavam um desempenho inferior, foram otimizados e atingiram melhores resultados comparados a outros algoritmos. Isso destaca a import√¢ncia de se utilizar uma abordagem robusta, como a valida√ß√£o cruzada, para avaliar o desempenho de maneira mais confi√°vel.

Al√©m disso, a an√°lise de import√¢ncia das vari√°veis revelou informa√ß√µes interessantes sobre as caracter√≠sticas mais influentes na decis√£o de compra. Para a maioria dos modelos, vari√°veis como ***"An√∫ncio Clicado"*** demonstraram ter um peso significativo na previs√£o de compra, enquanto vari√°veis como ***"Tempo no Site (min)"*** e **"Renda Anual (em $)"** n√£o mostraram ser t√£o indicativas, desafiando algumas hip√≥teses iniciais e mostrando a complexidade dos dados.

Alguns passos que poderiam ser adotados para melhorar a cria√ß√£o dos modelos incluem o balanceamento das classes, uma vez que h√° um desequil√≠brio significativo entre as classes alvo ***(n√£o comprou (0) - 134 registros e comprou (1) - 60 registros)***. O balanceamento adequado √© essencial para evitar que o modelo desenvolva um vi√©s em rela√ß√£o √† classe majorit√°ria. Al√©m disso, outro ponto importante seria a normaliza√ß√£o dos dados. Observa-se que certos atributos est√£o em escalas muito diferentes ‚Äî como a coluna ***"Renda Anual"***, que est√° na casa das centenas de milhas, enquanto ***"Tempo no site"*** est√° na casa das dezenas. A normaliza√ß√£o dessas vari√°veis √© fundamental, pois evita que o modelo atribua maior import√¢ncia a vari√°veis com magnitudes mais altas, o que pode distorcer os resultados e comprometer a performance do modelo.

Os pr√≥ximos passos, al√©m desses citados anteriormente, envolvem explorar ainda mais o desempenho dos modelos, testando novos hiperpar√¢metros e experimentando diferentes abordagens de tratamento de dados. Isso incluiria a incorpora√ß√£o de t√©cnicas de engenharia de atributos, ajustes finos nos modelos e a avalia√ß√£o de novas estrat√©gias de pr√©-processamento para otimizar ainda mais a acur√°cia e a generaliza√ß√£o dos modelos.


## üõ† Ferramentas
- Python 
- Bibliotecas 
    - Pandas
    - NumPy
    - YData Profiling
    - Scikit Learn 
    - Seaborn
    - Matplotlib
      
## Refer√™ncias
- [Pandas](https://pandas.pydata.org/)
- [NumPy](https://numpy.org/)
- [YData Profiling](https://github.com/ydataai/ydata-profiling)
- [Scikit Learn](https://scikit-learn.org/stable/index.html)
- [Seaborn](https://seaborn.pydata.org/)
- [Matplotlib](https://matplotlib.org/)


## Autor

- [@pedrohspassos](https://github.com/pedrohspassos)

